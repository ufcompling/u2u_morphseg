#
# Docstrings generated by VS Code Python Docstring Generator and modified by user
#

import os, argparse, shutil
import sklearn_crfsuite
import pickle
import statistics
from typing import TypeAlias, TypedDict, Literal, cast

# Unused Libraries:
# from sklearn.model_selection import train_test_split
# from collections import Counter
# from sklearn import metrics
# import matplotlib.pyplot as plt
# from sklearn.metrics import precision_recall_fscore_support
# from scipy.special import rel_entr

# Type Hinting
Word: TypeAlias = str
Morph: TypeAlias = str
MorphList: TypeAlias = list[str]
PredictionLabel: TypeAlias = Literal['B', 'M', 'E', 'S', '[', ']']

CharFeatures: TypeAlias = dict[str, int]
WordFeatures: TypeAlias = list[CharFeatures]
DatasetFeatures: TypeAlias = list[WordFeatures]

WordLabels: TypeAlias = list[PredictionLabel]
DatasetLabels: TypeAlias = list[WordLabels]

WordChars: TypeAlias = list[str]
DatasetChars: TypeAlias = list[WordChars]

ConfidenceScore: TypeAlias = float
ConfidenceData: TypeAlias = tuple[Word, list[Morph], ConfidenceScore]

CharMarginals: TypeAlias = dict[PredictionLabel, float]
WordMarginals: TypeAlias = list[CharMarginals]
DatasetMarginals: TypeAlias = list[WordMarginals]

BMESDict: TypeAlias = dict[Word, str]

class DatasetInfo(TypedDict):
	words: list[Word]
	morphs: list[MorphList]
	bmes: BMESDict

class DataDict(TypedDict):
	train: DatasetInfo
	test: DatasetInfo
	select: DatasetInfo

def main() -> None:

	args: argparse.Namespace = parse_arguments()
	sub_datadir: str = setup_datadirs(args)

	# Define file paths
	PATHS: dict[str, str] = {
		# Data gathering file paths
		'TRAIN_TGT': f'{sub_datadir}/train.{args.initial_size}.tgt',
		'TEST_TGT': f'{args.datadir}/{args.lang}/test.full.tgt',
		'SELECT_TGT': f'{sub_datadir}/select.{args.initial_size}.tgt',
		# Prediction saving file paths
		'TEST_PRED': f'{sub_datadir}/test.full.pred',
		'SELECT_PRED': f'{sub_datadir}/select.{args.initial_size}.pred',
		# Source file paths
		'TRAIN_SRC': f'{sub_datadir}/train.{args.initial_size}.src',
		'TEST_SRC': f'{args.datadir}/{args.lang}/test.full.src',
		'SELECT_SRC': f'{sub_datadir}/select.{args.initial_size}.src',
		# Evaluation file paths
		'EVAL_FILE': f'{sub_datadir}/eval.txt'	
	}

	# Gather words, morphs, and bmes
	data: DataDict = process_data(PATHS['TRAIN_TGT'], PATHS['TEST_TGT'], PATHS['SELECT_TGT'])
	
	# Build and evaluate the model
	Y_test_predict, Y_select_predict = build_and_output_crf(sub_datadir, args, data)

	# Outputting predictions for the test and the select file
	test_predictions: list[MorphList] = reconstruct_predictions(Y_test_predict, data['test']['words'])
	save_predictions(test_predictions, PATHS['TEST_PRED'])

	if os.path.exists(PATHS['SELECT_SRC']):
		select_predictions: list[MorphList] = reconstruct_predictions(Y_select_predict, data['select']['words'])	
		save_predictions(select_predictions, PATHS['SELECT_PRED'])

	# Overall evaluation metrics
	average_precision, average_recall, average_f1 = evaluate_predictions(data['test']['morphs'], test_predictions)
	with open(PATHS['EVAL_FILE'], 'w') as f:
		f.write(f'Precision: {average_precision}\n')
		f.write(f'Recall: {average_recall}\n')
		f.write(f'F1: {average_f1}\n')

	print('Complete!')
	print(f'  Language: {args.lang.title()}')
	print(f'  Initial Size: {args.initial_size}')
	print(f'  Average Precision: {average_precision}')
	print(f'  Average Recall: {average_recall}')
	print(f'  Average F1 Score: {average_f1}')

### Parsing Arguments ###
def parse_arguments() -> argparse.Namespace:
	"""
	Parse command-line arguments.
	
	:return: Parsed arguments
	:rtype: argparse.Namespace
	"""
	parser: argparse.ArgumentParser = argparse.ArgumentParser()
	parser.add_argument('--datadir', type = str, default = 'data', help = 'path to data')
	parser.add_argument('--lang', type = str, default = 'lang', help = 'language')
	parser.add_argument('--initial_size', type = str, default = '100', help = 'data initial_size to start AL iteration')
	parser.add_argument('--seed', type = str, default = '0', help = 'different initial training sets')
	parser.add_argument('--method', type = str, default = 'al')
	parser.add_argument('--select_interval', type = int, default = 50, help = 'how much data to select in each AL iteration; 50, 100, maybe larger')
	parser.add_argument('--select_size', type = int, default = 0, help = 'how much data have selected from all AL iterations thus far')
	parser.add_argument('--d', type = int, default = 4, help = 'delta; context window to consider for feature set construction')
	parser.add_argument('--e', type = float, default = 0.001, help = 'epsilon parameter for training CRF; may not use this in training')
	parser.add_argument('--i', type = int, default = 100, help = 'maximum number of iterations for training CRF')

	return parser.parse_args()

### Set up directories ###
def read_file(file_path: str) -> str:
	"""
	Reads the content of a file.
		
	:param file_path: Path to the file
	:type file_path: str
	:return: Content of the file
	:rtype: str
	"""
	with open(file_path, 'r', encoding='utf-8') as f:
		return f.read()
	
def write_file(file_path: str, content: str) -> None:
	"""
	Writes content to a file.
	
	:param file_path: Path to the file
	:type file_path: str
	:param content: Content to write to the file
	:type content: str
	"""
	with open(file_path, 'w', encoding='utf-8') as f:
		f.write(content)

def setup_datadirs(args: argparse.Namespace) -> str:
	"""
	Sets up data directories for the current iteration of active learning.
	
	:param args: Command-line arguments
	:type args: argparse.Namespace
	:return: File path of the sub data directory
	:rtype: str
	"""
	# Data directory for the current iteration
	sub_datadir: str = f'{args.datadir}/{args.lang}/{args.initial_size}/{args.seed}/{args.method}/{args.select_interval}/select{args.select_size}'
	if not os.path.exists(sub_datadir):
		os.makedirs(sub_datadir)

	if args.select_size != 0:
		# Data directory for the previous iteration
		prev_datadir: str = f'{args.datadir}/{args.lang}/{args.initial_size}/{args.seed}/{args.method}/{args.select_interval}/select{int(args.select_size) - int(args.select_interval)}'
		
		# Labeled set = previous training set + previous increment
		train_src: str = read_file(f'{prev_datadir}/train.{args.initial_size}.src')
		increment_src: str = read_file(f'{prev_datadir}/increment.src')
		write_file(f'{sub_datadir}/train.{args.initial_size}.src', train_src + increment_src)

		train_tgt: str = read_file(f'{prev_datadir}/train.{args.initial_size}.tgt')
		increment_tgt: str = read_file(f'{prev_datadir}/increment.tgt')
		write_file(f'{sub_datadir}/train.{args.initial_size}.tgt', train_tgt + increment_tgt)
		
		# Unlabeled set = previous residual
		shutil.copy(f'{prev_datadir}/residual.src', f'{sub_datadir}/select.{args.initial_size}.src')
		shutil.copy(f'{prev_datadir}/residual.tgt', f'{sub_datadir}/select.{args.initial_size}.tgt')

	return sub_datadir

### Gathering Data ###
def get_line_morphs(line: str) -> tuple[Word, MorphList]:
	"""
	Extracts the word and its morphemes from a line.
	
	:param line: Line of text containing a segmented word
	:type line: str
	:return: The unsegmented word and its morphemes
	:rtype: tuple[Word, MorphList]
	"""
	toks: list[str] = line.strip().split()
	morphs: MorphList = ''.join(toks).split('!')
	word: Word = ''.join(m for m in morphs)
	return word, morphs

def get_bmes_labels(morphs: MorphList) -> str:
	"""
	Generates BMES labels for a list of morphemes.
	
	:param morphs: List of morphemes
	:type morphs: MorphList
	:return: BMES labels for each character in the word
	:rtype: str
	"""
	label: list = []

	for morph in morphs:
		if len(morph) == 1:
			label.append('S')
		else:
			label.append('B')

			for _ in range(len(morph)-2):
				label.append('M')

			label.append('E')

	return ''.join(label)

def load_file_data(file_path: str | None) -> tuple[list[Word], list[MorphList], BMESDict]:
	"""
	Loads words, morphemes, and BMES labels from a file.
	
	:param file_path: Path to the file to be loaded
	:type file_path: str | None
	:return: List of words, List of morphemes, and BMES labels
	:rtype: tuple[list[Word], list[MorphList], BMESDict]
	"""
	words: list[Word] = []
	morphs: list[MorphList] = []
	bmes: BMESDict = dict()

	if not file_path or not os.path.exists(file_path):
		return words, morphs, bmes

	with open(file_path, encoding='utf-8') as f:
		for line in f:
			word, line_morphs = get_line_morphs(line)
			bmes_labels: str = get_bmes_labels(line_morphs)

			words.append(word)
			morphs.append(line_morphs)
			bmes[word] = bmes_labels
		
	return words, morphs, bmes

def process_data(train_path: str, test_path: str, select_path: str | None = None) -> DataDict:  # *.tgt files 
	"""
	Processes training, testing, and selection data from files.
	
	:param train_path: Path to the training data file
	:type train_path: str
	:param test_path: Path to the testing data file
	:type test_path: str
	:param select_path: Path to the selection data file (optional)
	:type select_path: str | None
	:return: Dictionary containing training, testing, and selection data
	:rtype: DataDict
	"""
	train_words, train_morphs, train_bmes = load_file_data(train_path)
	test_words, test_morphs, test_bmes = load_file_data(test_path)
	select_words, select_morphs, select_bmes = load_file_data(select_path)

	return {
		'train': {
			'words': train_words,
			'morphs': train_morphs,
			'bmes': train_bmes
		},
		'test': {
			'words': test_words,
			'morphs': test_morphs,
			'bmes': test_bmes
		},
		'select': {
			'words': select_words,
			'morphs': select_morphs,
			'bmes': select_bmes
		}
	}

### Computing Features ###

VOWELS: set[str] = set('aeiouAEIOU')

# Common English affixes â€” helps the CRF recognize known morpheme patterns.
# For non-English languages, these won't fire and the model falls back to
# character-level features, so this is safe to leave in.
COMMON_PREFIXES: tuple[str, ...] = ('un', 're', 'in', 'im', 'dis', 'en', 'em', 'non', 'pre', 'mis', 'over', 'under', 'out', 'sub')
COMMON_SUFFIXES: tuple[str, ...] = ('ing', 'ed', 'ly', 'er', 'est', 'ness', 'ment', 'ful', 'less', 'tion', 'sion', 'able', 'ible', 'ous', 'ive', 'al', 'en', 'ish', 'dom', 'ship')

def get_char_features(bounded: Word, i: int, delta: int) -> CharFeatures:
	"""
	Generates character features for a given position in a bounded word.

	Produces n-gram, positional, phonological, and affix-awareness features.
	The original implementation only used n-grams + absolute start position,
	which starved the CRF of structural signal â€” especially on small training sets.
	
	:param bounded: The bounded word (with [ and ] markers)
	:type bounded: Word
	:param i: The index of the character in the bounded word
	:type i: int
	:param delta: The number of characters to consider for right and left features
	:type delta: int
	:return: Character features for the given position
	:rtype: CharFeatures
	"""
	char_dict: CharFeatures = {}
	char: str = bounded[i]
	word_len: int = len(bounded) - 2  # exclude [ and ]

	# --- Original n-gram features (right context) ---
	for j in range(delta):
		char_dict[f'right_{bounded[i:i+j+1]}'] = 1

	# --- Original n-gram features (left context) ---
	for j in range(delta):
		if i - j - 1 < 0: 
			break
		char_dict[f'left_{bounded[i-j-1:i]}'] = 1

	# --- Positional features ---
	char_dict[f'pos_start_{i}'] = 1
	char_dict[f'pos_end_{len(bounded) - i - 1}'] = 1   # distance from word end

	if word_len > 0:
		# Bucketed relative position (quarters) â€” generalizes across word lengths
		rel_pos: int = int((max(i - 1, 0) / word_len) * 4)
		char_dict[f'pos_bucket_{rel_pos}'] = 1

	char_dict[f'word_len_{min(word_len, 15)}'] = 1  # capped to avoid feature explosion

	# --- Character identity ---
	char_dict[f'char_{char}'] = 1

	# --- Phonological features ---
	if char not in ('[', ']'):
		is_vowel: bool = char in VOWELS
		char_dict['is_vowel'] = 1 if is_vowel else 0
		char_dict['is_consonant'] = 0 if is_vowel else 1

		# Vowel-consonant transitions often mark syllable/morpheme boundaries
		if i > 0 and bounded[i-1] not in ('[', ']'):
			prev_vowel: bool = bounded[i-1] in VOWELS
			if is_vowel != prev_vowel:
				char_dict['vc_transition'] = 1

		# Consonant cluster detection â€” clusters often don't span morpheme boundaries
		if not is_vowel and i > 0 and bounded[i-1] not in VOWELS | {'[', ']'}:
			char_dict['in_consonant_cluster'] = 1

	# --- Affix awareness features ---
	# Fire when the current position aligns with a known affix boundary.
	# These are soft hints, not hard rules â€” the CRF learns weights for them.
	if char not in ('[', ']'):
		inner_pos: int = i - 1  # 0-indexed position within the actual word
		raw_word: str = bounded[1:-1]

		for pfx in COMMON_PREFIXES:
			if raw_word.startswith(pfx) and inner_pos == len(pfx) - 1:
				char_dict[f'at_prefix_end_{pfx}'] = 1
			if raw_word.startswith(pfx) and inner_pos == len(pfx):
				char_dict[f'after_prefix_{pfx}'] = 1
				# Stem length after prefix â€” short stems suggest false prefix.
				# "re" + "ach" (3) is suspicious, "re" + "check" (5) is plausible.
				stem_len: int = word_len - len(pfx)
				char_dict[f'stem_after_pfx_{min(stem_len, 8)}'] = 1

		for sfx in COMMON_SUFFIXES:
			if raw_word.endswith(sfx) and inner_pos == word_len - len(sfx):
				char_dict[f'at_suffix_start_{sfx}'] = 1
				stem_len_sfx: int = word_len - len(sfx)
				char_dict[f'stem_before_sfx_{min(stem_len_sfx, 8)}'] = 1

			# Fires when the remaining characters from this position START
			# with a known suffix. Unlike at_suffix_start which only fires
			# for the LAST suffix (word.endswith), this catches INNER suffixes
			# in compound words:
			#   hopelessly pos 4: remainder="lessly" starts with "less" ✓
			#   hopelessly pos 8: remainder="ly" starts with "ly" ✓
			#   peacefully pos 5: remainder="fully" starts with "ful" ✓
			# Also prevents off-by-one errors (brigh!ten → bright!en) by
			# only firing at the exact suffix start position.
			if inner_pos < word_len:
				remainder: str = raw_word[inner_pos:]
				if remainder.startswith(sfx):
					char_dict[f'suffix_here_{sfx}'] = 1

	# --- Cross-boundary bigram features ---
	# The character pair spanning a potential boundary is the single most
	# discriminative signal for real vs. fake affix boundaries. E.g.,
	# "agree!ment" has cross-bigram "em" at the boundary, while "garment"
	# has "rm" â€” the CRF can learn which pairs occur at real boundaries.
	if char not in ('[', ']'):
		if i > 1 and bounded[i-1] not in ('[',):
			char_dict[f'bigram_{bounded[i-1]}{char}'] = 1
		if i < len(bounded) - 1 and bounded[i+1] not in (']',):
			char_dict[f'bigram_{char}{bounded[i+1]}'] = 1

	# --- Doubled consonant detection ---
	# Words like "kitten", "mitten", "flatten", "written" have doubled
	# consonants immediately before the "-en" ending. These are almost never
	# real stem+suffix boundaries â€” the doubling is orthographic, not
	# morphological. This feature gives the CRF a direct signal.
	if char not in ('[', ']') and i >= 2:
		if bounded[i-1] == char and char not in VOWELS:
			char_dict['doubled_consonant'] = 1
		if bounded[i-1] not in ('[', ']') and i >= 3 and bounded[i-2] == bounded[i-1] and bounded[i-1] not in VOWELS | {'[', ']'}:
			char_dict['after_doubled_consonant'] = 1

	return char_dict

def get_word_features(word: Word, bmes: BMESDict, delta: int) -> tuple[WordFeatures, WordLabels, WordChars]:
	"""
	Generates features, labels, and characters for a given word.
	
	:param word: The word to generate features for
	:type word: Word
	:param bmes: The BMES labels for each character in the word
	:type bmes: BMESDict
	:param delta: The number of characters to consider for right and left features
	:type delta: int
	:return: Features, labels, and characters for the given word
	:rtype: tuple[WordFeatures, WordLabels, WordChars]
	"""
	bounded_word: Word = f'[{word}]' # <w> and <\w> replaced with [ and ], respectively
	features: WordFeatures = [] # list (word) of dicts (chars)
	labels: WordLabels = [] # list (word) of labels (chars)
	word_chars: WordChars = [] # list (learning set) of list (word) of chars
	
	for i in range(len(bounded_word)):
		char_dict: CharFeatures = get_char_features(bounded_word, i, delta)
		features.append(char_dict)

		char: str = bounded_word[i]
		word_chars.append(char)

		if char in ['[', ']']: # labeling start and end
			labels.append(cast(PredictionLabel, char))
		else: # labeling chars
			labels.append(cast(PredictionLabel, bmes[word][i-1]))

	return features, labels, word_chars

def get_features(words: list[Word], bmes: BMESDict, delta: int) -> tuple[DatasetFeatures, DatasetLabels, DatasetChars]:
	"""
	Generates features, labels, and characters for a list of words.
	
	:param words: The list of words to generate features for
	:type words: list[Word]
	:param bmes: The BMES labels for each character in each word
	:type bmes: BMESDict
	:param delta: The number of characters to consider for right and left features
	:type delta: int
	:return: Features, labels, and characters for the given list of words
	:rtype: tuple[DatasetFeatures, DatasetLabels, DatasetChars]
	"""
	X: DatasetFeatures = [] # list (learning set) of list (word) of dicts (chars), INPUT for crf
	Y: DatasetLabels = [] # list (learning set) of list (word) of labels (chars), INPUT for crf
	dataset_chars: DatasetChars = [] # list (learning set) of list (word) of chars

	for word in words:
		features, labels, word_chars = get_word_features(word, bmes, delta)
		X.append(features)
		Y.append(labels)
		dataset_chars.append(word_chars)

	return X, Y, dataset_chars

### Sorting Data based on Confidence ###
def get_confidence_scores(words: list[Word], predictions: DatasetLabels, marginals: DatasetMarginals) -> list[ConfidenceScore]:
	"""
	Calculates confidence scores for a list of words based on predictions and marginals.
	
	:param words: The list of words to calculate confidence scores for
	:type words: list[Word]
	:param predictions: The predictions for each word in the list
	:type predictions: DatasetLabels
	:param marginals: The marginal probabilities for each word in the list
	:type marginals: DatasetMarginals
	:return: The confidence scores for each word in the list
	:rtype: list[ConfidenceScore]
	"""
	confscores: list[ConfidenceScore] = []
	for word, prediction, marginal in zip(words, predictions, marginals):
		# Remove '[' and ']' so that the characters match up with the labels
		boundless_pred, boundless_marg = prediction[1:-1], marginal[1:-1]
		confscores.append(sum(boundless_marg[i][label] for i, label in enumerate(boundless_pred)) / len(word))

	return confscores

def sort_by_confidence(words: list[Word], morphs: list[MorphList], confscores: list[ConfidenceScore]) -> list[ConfidenceData]:
	"""
	Sorts words, morphemes, and confidence scores by confidence scores.
	
	:param words: The list of words to sort
	:type words: list[Word]
	:param morphs: The list of morpheme lists to sort
	:type morphs: list[MorphList]
	:param confscores: The list of confidence scores to sort by
	:type confscores: list[ConfidenceScore]
	:return: The sorted list of (word, morphs, confidence) tuples
	:rtype: list[ConfidenceData]
	"""
	# Sort words/morphs by their confidence
	with_confidence: list[ConfidenceData] = sorted(zip(words, morphs, confscores), key=lambda x: x[2])

	# For debugging:
	# SEPARATOR = '|'
	# sorted_words, sorted_morphs, sorted_confidence = zip(*with_confidence)
	# datastring = []
	# for i in range(len(sorted_words)):
	# 	pairs = list(zip(sorted_words[i], sorted_morphs[i]))
	# 	info = ' '.join(pair[0] + SEPARATOR + pair[1] for pair in pairs) + '\t' + str(sorted_confidence[i])
	# 	datastring.append(info)

	return with_confidence

### Building Models ###

def balance_training_data(
	X_train: DatasetFeatures,
	Y_train: DatasetLabels,
	target_ratio: float = 0.30,
) -> tuple[DatasetFeatures, DatasetLabels]:
	"""
	Oversample monomorphemic words to fix class imbalance.

	With 80 training words split 64 poly / 16 mono (80/20), the CRF sees 4x
	more "split here" examples than "don't split." It learns to always segment
	anything that looks like a suffix. This is the direct cause of false
	boundary errors on trap words (kitchen, wicked, harness, etc).

	Fix: duplicate monomorphemic examples until they make up ~30% of training.
	At 30% the CRF gets enough "don't split" signal to fix the worst false
	boundaries without becoming too conservative about real ones.

	At 40% the model over-corrects — it starts suppressing real boundaries
	like fool!ish and self!ish. 30% is the empirical sweet spot.

	Auto-deactivates when the natural ratio exceeds the target, which happens
	around cycle 3 (~280 words) as more annotated data comes in.

	:param X_train: Training features
	:param Y_train: Training labels
	:param target_ratio: Desired minimum fraction of monomorphemic words
	:return: Balanced (X_train, Y_train)
	"""
	if len(X_train) == 0:
		return X_train, Y_train

	# Identify monomorphemic vs polymorphemic words by label sequence.
	# Mono words have no B label after position 0 (inner labels are all M/E/S).
	mono_indices: list[int] = []
	poly_indices: list[int] = []

	for i, labels in enumerate(Y_train):
		inner = labels[1:-1]  # strip [ and ]
		has_boundary = any(lbl == 'B' for lbl in inner[1:])
		if has_boundary:
			poly_indices.append(i)
		else:
			mono_indices.append(i)

	n_mono = len(mono_indices)
	n_poly = len(poly_indices)
	total = n_mono + n_poly

	if total == 0 or n_mono == 0:
		return X_train, Y_train

	current_ratio = n_mono / total
	if current_ratio >= target_ratio:
		return X_train, Y_train

	# Calculate exactly how many additional mono samples we need.
	# We want: (n_mono + extra) / (total + extra) >= target_ratio
	# Solving: extra = ceil((target_ratio * n_poly - n_mono * (1 - target_ratio)) / (1 - target_ratio))
	# Simplified: extra = ceil((target_ratio * total - n_mono) / (1 - target_ratio))
	import math
	extra_needed = math.ceil((target_ratio * total - n_mono) / (1 - target_ratio))
	extra_needed = min(extra_needed, n_mono * 4)  # cap at 4x original mono count

	# Add mono samples one at a time, cycling through the list
	balanced_X: DatasetFeatures = list(X_train)
	balanced_Y: DatasetLabels = list(Y_train)

	for i in range(extra_needed):
		idx = mono_indices[i % n_mono]
		balanced_X.append(X_train[idx])
		balanced_Y.append(Y_train[idx])

	new_mono = n_mono + extra_needed
	new_total = total + extra_needed
	print(f"  Balance: {n_mono} mono / {total} total ({current_ratio:.0%}) "
		  f"→ {new_mono} mono / {new_total} total ({new_mono/new_total:.0%})")

	return balanced_X, balanced_Y


def build_crf(sub_datadir: str, X_train: DatasetFeatures, Y_train: DatasetLabels, max_iterations: int = 100) -> sklearn_crfsuite.CRF:
	"""
	Builds and trains a CRF model.

	Regularization (c1/c2) is scaled based on training set size. With small
	datasets (<200 words), the original c1=c2=0.1 caused heavy underfitting.
	Lowering these lets the model actually learn the patterns present in the data
	without overfitting on the eval set â€” CRFs are inherently regularized by the
	structured prediction objective.
	
	:param sub_datadir: The subdirectory to save the model in
	:type sub_datadir: str
	:param X_train: The training features
	:type X_train: DatasetFeatures
	:param Y_train: The training labels
	:type Y_train: DatasetLabels
	:param max_iterations: The maximum number of iterations for training
	:type max_iterations: int
	:return: The trained CRF model
	:rtype: CRF
	"""
	n_samples: int = len(X_train)

	# Scale regularization to dataset size. These values were found empirically:
	# - tiny (<100):  nearly unregularized â€” let the model memorize what little it has
	# - small (<500): light regularization
	# - larger:       standard values
	if n_samples < 100:
		c1, c2 = 0.01, 0.01
	elif n_samples < 500:
		c1, c2 = 0.05, 0.05
	else:
		c1, c2 = 0.1, 0.1

	crf: sklearn_crfsuite.CRF = sklearn_crfsuite.CRF(
		algorithm='lbfgs',
		c1=c1,
		c2=c2,
		max_iterations=max_iterations,
		all_possible_transitions=True
	)
	crf.fit(X_train, Y_train)
	with open(f'{sub_datadir}/crf.model', 'wb') as f:
		pickle.dump(crf, f)

	return crf

# â”€â”€ Filtered Self-Training (semi-supervised bootstrap) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Prefix patterns that have high false-positive rates on monomorphemic trap
# words (uncle, relax, until, remain, etc.). Any pseudo-label placing a
# boundary right at these prefix lengths gets rejected.
_TRAP_PREFIXES: dict[str, int] = {
	'un': 2, 're': 2, 'in': 2, 'im': 2,
	'en': 2, 'em': 2, 'dis': 3, 'mis': 3,
}

# Suffix patterns common in monomorphemic words when the stem is short.
# "wick!ed" (stem=4), "har!ness" (stem=3) -- almost always wrong at stem<=3.
_TRAP_SUFFIXES: dict[str, int] = {
	'er': 2, 'ed': 2, 'en': 2, 'al': 2, 'le': 2,
	'ness': 4, 'ish': 3,
}

def _is_safe_pseudo_label(word: Word, predicted_labels: WordLabels) -> bool:
	"""
	Determine if a pseudo-label is safe to include in self-training.

	Rejects predictions that place a boundary at:
	  1. A trap prefix position (re!lax, un!cle, etc.)
	  2. A trap suffix position with a short stem (har!ness, wick!ed, etc.)

	:param word: The surface word
	:param predicted_labels: BMES labels including [ and ] markers
	:return: True if safe for self-training
	"""
	inner = predicted_labels[1:-1]

	boundary_positions: list[int] = []
	for i, label in enumerate(inner):
		if (label == 'B' or label == 'S') and i > 0:
			boundary_positions.append(i)

	if not boundary_positions:
		return True

	word_lower = word.lower()
	first_boundary = boundary_positions[0]
	last_boundary = boundary_positions[-1]

	for pfx, pfx_len in _TRAP_PREFIXES.items():
		if word_lower.startswith(pfx) and first_boundary == pfx_len:
			return False

	for sfx, sfx_len in _TRAP_SUFFIXES.items():
		if word_lower.endswith(sfx) and last_boundary == len(word) - sfx_len:
			stem_len = len(word) - sfx_len
			if stem_len <= 3:
				return False

	return True


def self_train(sub_datadir: str, X_train: DatasetFeatures, Y_train: DatasetLabels,
			   select_words: list[Word], select_bmes: BMESDict, delta: int,
			   max_iterations: int = 100, rounds: int = 2,
			   confidence_threshold: float = 0.80, max_pseudo_ratio: float = 2.0) -> sklearn_crfsuite.CRF:
	"""
	Filtered semi-supervised self-training for CRF.

	Trains an initial CRF, predicts on the unlabeled pool, keeps only
	high-confidence pseudo-labels that pass a safety filter, and retrains
	on the combined set. Runs multiple rounds so each iteration produces
	better pseudo-labels from a better model.

	Activates when training set is small (<150 words), covering cycle 1
	(~80 words) where the model is most data-starved. By cycle 2 (~180
	words) real labels are sufficient and pseudo-labels add noise.

	:param sub_datadir: Directory to save the model
	:param X_train: Labeled training features
	:param Y_train: Labeled training labels
	:param select_words: Unlabeled pool words
	:param select_bmes: BMES dict for unlabeled pool
	:param delta: Feature window size
	:param max_iterations: CRF training iterations
	:param rounds: Self-training rounds (default 2)
	:param confidence_threshold: Minimum avg marginal to accept pseudo-label
	:param max_pseudo_ratio: Max ratio of pseudo:real labels
	:return: The trained CRF model
	"""
	crf: sklearn_crfsuite.CRF = build_crf(sub_datadir, X_train, Y_train, max_iterations)

	# Only self-train when data is truly scarce.
	if len(X_train) >= 150 or not select_words:
		return crf

	max_pseudo: int = int(len(X_train) * max_pseudo_ratio)
	current_X: DatasetFeatures = list(X_train)
	current_Y: DatasetLabels = list(Y_train)

	for rnd in range(rounds):
		X_unlabeled, _, _ = get_features(select_words, select_bmes, delta)
		if not X_unlabeled:
			break

		Y_pred: DatasetLabels = crf.predict(X_unlabeled)
		marginals: DatasetMarginals = crf.predict_marginals(X_unlabeled)
		conf_scores: list[ConfidenceScore] = get_confidence_scores(select_words, Y_pred, marginals)

		candidates = sorted(
			zip(X_unlabeled, Y_pred, conf_scores, select_words),
			key=lambda x: x[2], reverse=True
		)

		pseudo_X: DatasetFeatures = []
		pseudo_Y: DatasetLabels = []
		for x, y, conf, word in candidates:
			if conf < confidence_threshold:
				break
			if not _is_safe_pseudo_label(word, y):
				continue
			pseudo_X.append(x)
			pseudo_Y.append(y)
			if len(pseudo_X) >= max_pseudo:
				break

		if not pseudo_X:
			break

		print(f"  Self-train round {rnd+1}: +{len(pseudo_X)} pseudo-labels "
			f"(total {len(current_X) + len(pseudo_X)})")

		crf = build_crf(sub_datadir, current_X + pseudo_X, current_Y + pseudo_Y, max_iterations)

	return crf

def split_increment_residual(confidence_data: list[ConfidenceData], select_interval: int) -> tuple[list[ConfidenceData], list[ConfidenceData]]:
	"""
	Splits confidence data into increment and residual sets based on the selection interval.
	
	:param confidence_data: The list of (word, morphs, confidence) tuples to split
	:type confidence_data: list[ConfidenceData]
	:param select_interval: The number of items to include in the increment set
	:type select_interval: int
	:return: The increment and residual sets as lists of (word, morphs, confidence) tuples
	:rtype: tuple[list[ConfidenceData], list[ConfidenceData]]
	"""
	increment_data: list[ConfidenceData] = confidence_data[:select_interval]
	residual_data: list[ConfidenceData] = confidence_data[select_interval:]

	return increment_data, residual_data

def save_data(confidence_data: list[ConfidenceData], sub_datadir: str, file_name: str) -> None:
	"""
	Saves confidence data to source and target files.
	
	:param confidence_data: The list of (word, morphs, confidence) tuples to save
	:type confidence_data: list[ConfidenceData]
	:param sub_datadir: The subdirectory to save the files in
	:type sub_datadir: str
	:param file_name: The base name for the source and target files
	:type file_name: str
	"""
	if not confidence_data:
		# Write empty files so downstream path-existence checks stay consistent
		open(f'{sub_datadir}/{file_name}.src', 'w').close()
		open(f'{sub_datadir}/{file_name}.tgt', 'w').close()
		return

	words, morphs_list, _ = zip(*confidence_data)
	
	src_content: list[str] = [' '.join(word) + '\n' for word in words]
	with open(f'{sub_datadir}/{file_name}.src', 'w', encoding='utf-8') as src:
		src.writelines(src_content)

	tgt_content: list[str] = [' '.join('!'.join(morphs)) + '\n' for morphs in morphs_list]
	with open(f'{sub_datadir}/{file_name}.tgt', 'w', encoding='utf-8') as tgt:
		tgt.writelines(tgt_content)

def output_crf(crf: sklearn_crfsuite.CRF, sub_datadir: str, args: argparse.Namespace, data: DataDict, X_test: DatasetFeatures) -> tuple[DatasetLabels, DatasetLabels]:
	"""
	Outputs predictions from the CRF model and prepares data for active learning.

	:param crf: The trained CRF model
	:type crf: sklearn_crfsuite.CRF
	:param sub_datadir: The subdirectory to save output files in
	:type sub_datadir: str
	:param args: The command-line arguments
	:type args: argparse.Namespace
	:param data: The data dictionary containing train, test, and select data
	:type data: DataDict
	:param X_test: The test features
	:type X_test: DatasetFeatures
	:return: The predicted labels for the test and select sets
	:rtype: tuple[DatasetLabels, DatasetLabels]
	"""
	Y_test_predict: DatasetLabels = crf.predict(X_test)

	Y_select_predict: DatasetLabels = []
	if data['select']['words']:
		X_select, _, _ = get_features(data['select']['words'], data['select']['bmes'], args.d)
		Y_select_predict = crf.predict(X_select)

		marginals: DatasetMarginals = crf.predict_marginals(X_select)
		confscores: list[ConfidenceScore] = get_confidence_scores(data['select']['words'], Y_select_predict, marginals)
		conf_sorted_data: list[ConfidenceData] = sort_by_confidence(data['select']['words'], data['select']['morphs'], confscores)

		increment_data, residual_data = split_increment_residual(conf_sorted_data, args.select_interval)
		save_data(increment_data, sub_datadir, 'increment')
		save_data(residual_data, sub_datadir, 'residual')

	return Y_test_predict, Y_select_predict


def build_and_output_crf(sub_datadir: str, args: argparse.Namespace, data: DataDict) -> tuple[DatasetLabels, DatasetLabels]:
	"""
	Builds the CRF model and outputs predictions.
	
	:param sub_datadir: The subdirectory to save output files in
	:type sub_datadir: str
	:param args: The command-line arguments
	:type args: argparse.Namespace
	:param data: The data dictionary containing train, test, and select data
	:type data: DataDict
	:return: The predicted labels for the test and select sets
	:rtype: tuple[DatasetLabels, DatasetLabels]
	"""
	X_train, Y_train, _ = get_features(data['train']['words'], data['train']['bmes'], args.d)
	X_test, _, _ = get_features(data['test']['words'], data['test']['bmes'], args.d)

	# Balance poly/mono ratio to prevent over-segmentation
	X_train, Y_train = balance_training_data(X_train, Y_train)

	crf: sklearn_crfsuite.CRF = self_train(
		sub_datadir, X_train, Y_train,
		data['select']['words'], data['select']['bmes'], args.d,
		max_iterations=getattr(args, 'i', 100),
	)
	
	return output_crf(crf, sub_datadir, args, data, X_test)

# Going from predicted labels to predicted morphemes
def reconstruct_predictions(pred_labels: DatasetLabels, words: list[Word]) -> list[MorphList]:
	"""
	Reconstructs morpheme predictions from predicted labels.
	
	:param pred_labels: The predicted labels for each word
	:type pred_labels: DatasetLabels
	:param words: The list of words corresponding to the predicted labels
	:type words: list[Word]
	:return: The reconstructed morpheme predictions for each word
	:rtype: list[MorphList]
	"""
	predictions: list[MorphList] = []

	for pred, word in zip(pred_labels, words):

		# Remove '[' and ']' and split by end markers (E)
		labels: list[str] = [label for label in ''.join(w for w in pred[1:-1]).split('E') if label]
		
		new_labels: list[str] = []
		for tok in labels:
			
			# If nothing is marked single, then it's fine; add back the end marker
			if 'S' not in tok:
				tok += 'E'
				new_labels.append(tok)

			# Otherwise, if the tok only contains single markers, then add that many single markers
			elif (s_count := tok.count('S')) == len(tok):
				new_labels.extend(['S'] * s_count)
			
			# Otherwise, append an S marker for the single morphemes or concatenate an end marker to each morpheme and add it
			else:
				for bmes_label in tok.split('S'):
					if bmes_label == '':
						new_labels.append('S')
					else:
						new_labels.append(bmes_label + 'E')

		morphs: MorphList = []
		prefix_length: int = 0
		for label in new_labels:
			tok_length: int = len(label)
			morphs.append(word[prefix_length:prefix_length+tok_length])
			prefix_length += tok_length

		predictions.append(morphs)

	return predictions

# Save predictions
def save_predictions(predictions: list[MorphList], file_path: str) -> None:
	"""
	Saves morpheme predictions to a file.
	
	:param predictions: The list of predicted morpheme lists
	:type predictions: list[MorphList]
	:param file_path: The path to the output file
	:type file_path: str
	"""
	pred_content: list[str] = [' '.join('!'.join(morphs)) + '\n' for morphs in predictions]
	with open(file_path, 'w', encoding = 'utf-8') as f:
		f.writelines(pred_content)

# Evaluate predictions with statistical metrics (precision, recall, F1 score)
def _morphs_to_boundaries(morphs: MorphList) -> set[int]:
	"""
	Convert a morpheme list to a set of boundary positions (character offsets
	where one morpheme ends and the next begins).

	Example: ["un", "help", "ful"] -> {2, 6}  (boundary after char 2, after char 6)

	:param morphs: List of morphemes for one word
	:type morphs: MorphList
	:return: Set of boundary character positions
	:rtype: set[int]
	"""
	boundaries: set[int] = set()
	offset: int = 0
	for morph in morphs[:-1]:  # no boundary after the last morpheme
		offset += len(morph)
		boundaries.add(offset)
	return boundaries

def calculate_metrics(y_true: MorphList, y_pred: MorphList) -> tuple[float, float, float]:
	"""
	Calculates precision, recall, and F1 score using boundary-based evaluation.

	The previous implementation used bag-of-morphemes matching (`if m in y_true`)
	which didn't respect position or multiplicity â€” a predicted morpheme "ed"
	would match any gold morpheme "ed" regardless of where it appeared, and
	duplicate predictions were counted as correct multiple times.

	Boundary-based evaluation is standard for morphological segmentation: we
	compare the set of character offsets where splits occur.

	:param y_true: The true morpheme list
	:type y_true: MorphList
	:param y_pred: The predicted morpheme list
	:type y_pred: MorphList
	:return: The precision, recall, and F1 score (0-100 scale)
	:rtype: tuple[float, float, float]
	"""
	gold_bounds: set[int] = _morphs_to_boundaries(y_true)
	pred_bounds: set[int] = _morphs_to_boundaries(y_pred)

	# Single-morpheme words have no boundaries â€” both sides agree trivially
	if not gold_bounds and not pred_bounds:
		return 100.0, 100.0, 100.0

	if not pred_bounds:
		return 0.0, 0.0, 0.0

	if not gold_bounds:
		return 0.0, 0.0, 0.0

	correct: int = len(gold_bounds & pred_bounds)
	precision: float = correct / len(pred_bounds) * 100
	recall: float = correct / len(gold_bounds) * 100
	f1: float = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0

	return round(precision, 2), round(recall, 2), round(f1, 2)

def evaluate_predictions(gold_word: list[MorphList], pred_word: list[MorphList]) -> tuple[float, float, float]:
	"""
	Evaluates predicted morphemes against gold standard morphemes using precision, recall, and F1 score.
	
	:param gold_word: The list of gold standard morpheme lists
	:type gold_word: list[MorphList]
	:param pred_word: The list of predicted morpheme lists
	:type pred_word: list[MorphList]
	:return: The average precision, recall, and F1 score across all words
	:rtype: tuple[float, float, float]
	"""
	precision_scores: list[float] = []
	recall_scores: list[float] = []
	f1_scores: list[float] = []

	for gold_morphs, pred_morphs in zip(gold_word, pred_word):
		precision, recall, f1 = calculate_metrics(gold_morphs, pred_morphs)
		precision_scores.append(precision)
		recall_scores.append(recall)
		f1_scores.append(f1)

	if not precision_scores:
		return 0.0, 0.0, 0.0

	average_precision, average_recall, average_f1 = (round(statistics.mean(x), 2) for x in (precision_scores, recall_scores, f1_scores))
	return average_precision, average_recall, average_f1


# ── Marginal-Based Post-Processing (v4.1) ────────────────────────────────────
#
# The dominant error type across all cycles is false boundaries at common suffix
# positions (kitchen→kitch!en, wicked→wick!ed, harness→har!ness). The CRF's
# marginal probabilities already encode uncertainty about these positions, but
# the Viterbi decoder picks the single best path regardless of margin.
#
# Post-processing inspects boundary positions after prediction. If a B label
# (morpheme start) sits at a common suffix position with:
#   1. Low marginal probability for B (the model isn't confident)
#   2. Short stem (≤4 chars — most trap words have stems of 3-4)
# then we flip B→M (continue the morpheme instead of starting a new one).
#
# This can only FIX false_boundary errors. It cannot create new errors except
# by occasionally missing a real boundary — but the threshold is conservative
# enough that this is rare.

_POSTPROCESS_SUFFIXES: dict[str, int] = {
	'er': 2, 'ed': 2, 'en': 2, 'al': 2, 'ly': 2, 'le': 2,
	'ness': 4, 'ment': 4, 'ish': 3, 'ful': 3, 'less': 4,
}

def postprocess_predictions(
	Y_predict: DatasetLabels,
	marginals: DatasetMarginals,
	words: list[Word],
	n_train: int = 0,
) -> DatasetLabels:
	"""
	Suppress low-confidence false boundaries at trap suffix positions.

	After the CRF predicts, checks each boundary at a common suffix position.
	If P(B) is below a threshold and the stem is short, flips B→M.

	Threshold and max_stem adapt to training size:
	  - Early cycles (<150 words): aggressive — threshold=0.70, max_stem=5
	    The model is undertrained and over-segments. Be skeptical of boundaries.
	  - Mid cycles (<300 words):   moderate — threshold=0.60, max_stem=5
	  - Late cycles (300+):        conservative — threshold=0.55, max_stem=5
	    Trust the model more as it's seen enough data.

	:param Y_predict: Raw predicted label sequences from CRF
	:param marginals: Per-position marginal probabilities from CRF
	:param words: Corresponding words
	:param n_train: Training set size (drives adaptive threshold)
	:return: Corrected label sequences
	"""
	# Adaptive threshold: more aggressive when training data is scarce
	if n_train < 150:
		threshold = 0.70
	elif n_train < 300:
		threshold = 0.60
	else:
		threshold = 0.55
	max_stem = 5

	corrected: DatasetLabels = []

	for pred, marg, word in zip(Y_predict, marginals, words):
		inner_pred = list(pred[1:-1])
		inner_marg = marg[1:-1]
		word_lower = word.lower()
		changed = False

		for sfx, sfx_len in _POSTPROCESS_SUFFIXES.items():
			if not word_lower.endswith(sfx):
				continue

			sfx_start = len(word) - sfx_len
			stem_len = sfx_start

			if stem_len > max_stem:
				continue

			if sfx_start < len(inner_pred) and inner_pred[sfx_start] == 'B':
				prob_b = inner_marg[sfx_start].get('B', 0.0)

				if prob_b < threshold:
					inner_pred[sfx_start] = 'M'
					changed = True

		if changed:
			corrected.append(cast(WordLabels, ['['] + inner_pred + [']']))
		else:
			corrected.append(pred)

	return corrected


def get_cycle_diagnostics(
	crf: 'sklearn_crfsuite.CRF',
	words: list[Word],
	Y_predict: DatasetLabels,
	marginals: DatasetMarginals,
	gold_morphs: list[MorphList],
	train_words: list[Word],
	train_bmes: BMESDict,
) -> dict:
	"""
	Generate diagnostic information about a training cycle for debugging.

	Returns a dict with:
	  - error_analysis: per-error-word breakdown with marginals at error positions
	  - training_coverage: which affix patterns are represented in training data
	  - confidence_calibration: accuracy at different confidence buckets
	  - top_features: highest-weight features for boundary vs non-boundary

	:param crf: Trained CRF model
	:param words: Eval words
	:param Y_predict: Predicted labels for eval words
	:param marginals: Marginal probabilities for eval words
	:param gold_morphs: Gold standard morpheme lists
	:param train_words: Training set words
	:param train_bmes: Training set BMES labels
	:return: Diagnostic dict
	"""
	diagnostics: dict = {}

	# --- Error analysis with marginals ---
	error_analysis: list[dict] = []
	pred_morphs_list = reconstruct_predictions(Y_predict, words)

	for word, gold, pred_labels, pred_morphs, marg in zip(
		words, gold_morphs, Y_predict, pred_morphs_list, marginals
	):
		if gold == pred_morphs:
			continue

		inner_marg = marg[1:-1]
		inner_pred = pred_labels[1:-1]

		# Find boundary positions in prediction
		pred_boundaries: list[int] = []
		for idx, label in enumerate(inner_pred):
			if label in ('B', 'S') and idx > 0:
				pred_boundaries.append(idx)

		# Find gold boundary positions
		gold_boundaries: set[int] = set()
		offset = 0
		for m in gold[:-1]:
			offset += len(m)
			gold_boundaries.add(offset)

		# Analyze each predicted boundary
		boundary_details: list[dict] = []
		for bp in pred_boundaries:
			prob_b = inner_marg[bp].get('B', 0.0)
			prob_m = inner_marg[bp].get('M', 0.0)
			is_correct = bp in gold_boundaries
			boundary_details.append({
				'position': bp,
				'prob_B': round(prob_b, 3),
				'prob_M': round(prob_m, 3),
				'correct': is_correct,
				'context': word[max(0,bp-2):bp+3],
			})

		error_analysis.append({
			'word': word,
			'gold': '!'.join(gold),
			'predicted': '!'.join(pred_morphs),
			'boundaries': boundary_details,
		})

	diagnostics['error_analysis'] = error_analysis

	# --- Training set affix coverage ---
	seen_prefixes: set[str] = set()
	seen_suffixes: set[str] = set()
	monomorphemic_count: int = 0

	for word in train_words:
		bmes_str = train_bmes.get(word, '')
		if 'B' not in bmes_str[1:]:  # No boundary after first char
			monomorphemic_count += 1

		for pfx in COMMON_PREFIXES:
			if word.lower().startswith(pfx) and len(word) > len(pfx) + 2:
				seen_prefixes.add(pfx)
		for sfx in COMMON_SUFFIXES:
			if word.lower().endswith(sfx) and len(word) > len(sfx) + 2:
				seen_suffixes.add(sfx)

	diagnostics['training_coverage'] = {
		'total_words': len(train_words),
		'monomorphemic': monomorphemic_count,
		'polymorphemic': len(train_words) - monomorphemic_count,
		'prefix_patterns_seen': sorted(seen_prefixes),
		'prefix_patterns_missing': sorted(set(COMMON_PREFIXES) - seen_prefixes),
		'suffix_patterns_seen': sorted(seen_suffixes),
		'suffix_patterns_missing': sorted(set(COMMON_SUFFIXES) - seen_suffixes),
	}

	# --- Feature weight summary (top 10 for B label) ---
	try:
		if hasattr(crf, 'state_features_'):
			b_weights = {}
			m_weights = {}
			for (attr, label), weight in crf.state_features_.items():
				if label == 'B':
					b_weights[attr] = weight
				elif label == 'M':
					m_weights[attr] = weight

			top_b = sorted(b_weights.items(), key=lambda x: abs(x[1]), reverse=True)[:15]
			top_m = sorted(m_weights.items(), key=lambda x: abs(x[1]), reverse=True)[:15]

			diagnostics['top_features'] = {
				'boundary_start_B': [{'feature': f, 'weight': round(w, 3)} for f, w in top_b],
				'morpheme_middle_M': [{'feature': f, 'weight': round(w, 3)} for f, w in top_m],
			}
	except Exception:
		diagnostics['top_features'] = {'note': 'Feature weights not available'}

	return diagnostics


if __name__ == '__main__':
	main()